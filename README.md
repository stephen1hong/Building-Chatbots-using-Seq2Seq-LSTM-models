# Building-Chatbots-using-Seq2Seq-LSTM-models
i.e., implementing an encoder-decoder RNN-based LSTM unit for a simple sequence-to-sequence question-answer task

* data preparation
* defining a seq2seq model that has 4 components: embedding layer, encoder, decoder, cost & optimizer
* hyperparameters
* training
* evaluation

---
Reference: Python Deep Learning projects, M. Lamons, R. Kumar, A. Nagaraja
